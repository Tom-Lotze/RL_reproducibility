{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions used in experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import time\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment: Windy gridworld\n",
    "Gives a reward of -1 for each step taken, while the final state is not reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/rl2020/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# from windy_gridworld import WindyGridworldEnv\n",
    "# env = WindyGridworldEnv()\n",
    "# env??\n",
    "\n",
    "import gym\n",
    "env = gym.envs.make(\"FrozenLake-v0\")\n",
    "env.env.__init__(is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy\n",
    "\n",
    "### Target policy (choose greedy vs non-greedy)\n",
    "Greedy policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q):\n",
    "        self.Q = Q\n",
    "    \n",
    "    def get_probs(self, state, action):\n",
    "        \"\"\"\n",
    "        Takes a state and an action and returns the probability of taking that action from \n",
    "        that state, under Q and a greedy policy\n",
    "        \"\"\"   \n",
    "        # for state and action only:\n",
    "        action_probs = self.Q[state]\n",
    "        max_indices = np.argwhere(action_probs == np.amax(action_probs))\n",
    "        \n",
    "        if action in max_indices:\n",
    "            prob = 1/len(max_indices)\n",
    "        else:\n",
    "            prob = 0\n",
    "        \n",
    "        return prob\n",
    "        \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "\n",
    "        best_actions = [i for i, j in enumerate([self.Q[obs][i] for i in range(4)]) \n",
    "                   if j == max([self.Q[obs][i] for i in range(4)])] \n",
    "\n",
    "        best_action = np.random.choice(best_actions)\n",
    "        \n",
    "        return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def get_probs(self, state, action):\n",
    "        # for one state and action \n",
    "        action_probs = self.Q[state]\n",
    "        max_indices = np.argwhere(action_probs == np.amax(action_probs))\n",
    "        # all probs are equal, give all equal probabilities\n",
    "        if len(max_indices) == len(action_probs):\n",
    "            return 1/len(max_indices)\n",
    "            \n",
    "        if action in max_indices:\n",
    "            prob = (1-self.epsilon)/len(max_indices)\n",
    "        else:\n",
    "            prob = epsilon / (len(action_probs) - len(max_indices))\n",
    "        \n",
    "        return prob\n",
    "        \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "#         if (obs == 13): \n",
    "#             print(self.Q[obs])\n",
    "        p = np.random.uniform()\n",
    "        if p > self.epsilon:\n",
    "            # choose one of the best actions\n",
    "            action = np.random.choice([i for i, j in enumerate(self.Q[obs]) if j == np.max(self.Q[obs])])\n",
    "        else:\n",
    "            # return a random action\n",
    "            action = np.random.randint(0,4)\n",
    "                \n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_episode(env, policy):\n",
    "    \"\"\"\n",
    "    A sampling routine. Given environment and a policy samples one episode and returns states, actions, rewards\n",
    "    and dones from environment's step function and policy's sample_action function as lists.\n",
    "\n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of lists (states, actions, rewards, dones). All lists should have same length. \n",
    "        state after the termination is not included in the list of states.\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    \n",
    "    # get a starting state\n",
    "    s = env.reset()\n",
    "    d = False\n",
    "    \n",
    "    # keep looping until done, don's save the terminal state\n",
    "    while not d:\n",
    "        states.append(s)\n",
    "        a = policy.sample_action(s)\n",
    "        s, r, d, _ = env.step(a)\n",
    "        \n",
    "        # save                \n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        dones.append(d)\n",
    "        \n",
    "\n",
    "    return states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of episode 0: 6\n"
     ]
    }
   ],
   "source": [
    "# check the length of episodes that are generated for eps greedy policy\n",
    "Q = np.zeros((env.env.nS, env.env.nA))\n",
    "bp = EpsilonGreedyPolicy(Q, epsilon=0.1)\n",
    "\n",
    "for episode in range(1):\n",
    "    trajectory_data = sample_episode(env, bp)\n",
    "    print(f\"length of episode {episode}: {len(trajectory_data[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_importance_sampling(env, behavior_policy, target_policy, num_episodes, weighted=False, discount_factor=1.0,\n",
    "                           sampling_function=sample_episode, epsilon=0.05, seed=42, \n",
    "                           analyse_states=[(0,2), (0,1), (14,2), (2,1)]):\n",
    "    \"\"\"\n",
    "    Monte Carlo prediction algorithm. Calculates the Q function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        behavior_policy: A policy used to collect the data.\n",
    "        target_policy: A policy which value function we want to estimate.\n",
    "        num_episodes: Number of episodes to sample.\n",
    "        weighted: Boolean flag to use weighted or ordinary importance sampling.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        sampling_function: Function that generates data from one episode.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps from (state, action) -> value.\n",
    "    \"\"\"\n",
    "\n",
    "    # set the current Q to a large negative value\n",
    "    Q = np.zeros((env.env.nS, env.env.nA))\n",
    "    if weighted:\n",
    "        C = np.zeros((env.env.nS, env.env.nA))\n",
    "    else:\n",
    "        returns_count = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    episode_lens = []\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    analysis_values = dict((k,[]) for k in analyse_states)\n",
    "    \n",
    "    # sample episodes\n",
    "    for i in tqdm(range(num_episodes), position=0):\n",
    "        # update behavioral and target policy\n",
    "        behavior_policy.Q = Q\n",
    "        target_policy.Q = Q        \n",
    "    \n",
    "        # sample episode with new behavioural function\n",
    "        states, actions, rewards, dones = sampling_function(env, behavior_policy)\n",
    "        \n",
    "        # save the episode length\n",
    "        episode_lens.append(len(states)) \n",
    "\n",
    "        G = 0        \n",
    "        W = 1\n",
    "        \n",
    "        # loop backwards over the trajectory\n",
    "        for i, timestep in enumerate(range(len(states)-1, -1, -1)):\n",
    "            s = states[timestep]\n",
    "            r = rewards[timestep]\n",
    "            a = actions[timestep]\n",
    "            G = discount_factor * G + r\n",
    "            \n",
    "            if weighted:\n",
    "                # add W to the sum of weights C\n",
    "                C[s][a] += W\n",
    "                Q[s][a] += W/C[s][a] * (G - Q[s][a])\n",
    "            else:\n",
    "                returns_count[s][a] += 1 \n",
    "                # use every visit incremental method\n",
    "                Q[s][a] += 1/returns_count[s][a] * W * (G - Q[s][a])\n",
    "\n",
    "            W *= (target_policy.get_probs(s, a)) / (behavior_policy.get_probs(s, a))        \n",
    "\n",
    "            if W == 0:\n",
    "                break\n",
    "\n",
    "        # store state values to analyse\n",
    "        for (s,a) in analyse_states:\n",
    "#             print(Q[s][a])\n",
    "            analysis_values[(s,a)].append(Q[s][a])\n",
    "            \n",
    "    return Q, episode_lens, analysis_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using ordinary importance sampling (5000 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:09<00:00, 548.78it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using weighted importance sampling (5000 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 842.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reproducible\n",
    "seed = 42\n",
    "\n",
    "# set other parameters\n",
    "epsilon = 0.2\n",
    "gamma = 0.99\n",
    "num_episodes = 5000\n",
    "Q = np.ones((env.env.nS, env.env.nA)) * 0\n",
    "behavioral_policy = EpsilonGreedyPolicy(Q, epsilon=epsilon)\n",
    "target_policy = GreedyPolicy(Q)\n",
    "\n",
    "# the episode length is equal to the negative return. \n",
    "print(f\"Updating Q using ordinary importance sampling ({num_episodes} episodes)\")\n",
    "Q_mc_ordinary, mc_ordinary_epslengths, mc_analysis_ordinary = mc_importance_sampling(env,\n",
    "                                                               behavioral_policy, target_policy, \n",
    "                                                               num_episodes, weighted=False,discount_factor=gamma, \n",
    "                                                               epsilon=epsilon, seed=seed)\n",
    "\n",
    "print(f\"Updating Q using weighted importance sampling ({num_episodes} episodes)\")\n",
    "Q_mc_weighted, mc_weighted_epslengths, mc_analysis_weighted = mc_importance_sampling(env,\n",
    "                                                               behavioral_policy, target_policy,\n",
    "                                                               num_episodes, weighted=True, discount_factor=gamma, \n",
    "                                                               epsilon=epsilon, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting episode length ordinary: 6\n",
      "resulting episode length weighted: 6\n"
     ]
    }
   ],
   "source": [
    "# check how long an episode takes under the found Q function\n",
    "greedy_ordinary = GreedyPolicy(Q_mc_ordinary)\n",
    "greedy_weighted = GreedyPolicy(Q_mc_weighted)\n",
    "\n",
    "ordinary_episode = sample_episode(env, greedy_ordinary)\n",
    "weighted_episode = sample_episode(env, greedy_weighted)\n",
    "\n",
    "print(f\"resulting episode length ordinary: {len(ordinary_episode[0])}\")\n",
    "print(f\"resulting episode length weighted: {len(weighted_episode[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting episode lengths during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2dd5gUxdaH39qMS4YlSViUICBRJIhkARUFMaMoXAPXjFmMYLqiYsbEh4IZI0ZQkCBRkkjOsOScYdk0U98f3ZPDzuzO7kzvnvd55pnu6qruUxN+XX2q6pTSWiMIgiBYj7hoGyAIgiAUDBFwQRAEiyICLgiCYFFEwAVBECyKCLggCIJFEQEXBEGwKCLgQpGhlJqilBoc4XOOVEp9XsCyGUqpiyJpT4jXTVdKaaVUQnFfWyjZiIALQTFF77RS6qTba0woZbXWl2itPylqG2ONorpRKKW6mTeCH7zSW5rps9zSlFLqPqXUKqXUKaXUTqXUt0qp5pG2S4ge0iIQQuFyrfWf0TZCAOAAcIFSqorW+pCZNhjY4JXvLaAvcDswD4gHBphpK4vJVqGIkRa4UGCUUkOUUvOUUu8opY4ppdYppXq6HZ+llLrN3G6glPrLzHdQKfW1W74LlFKLzWOLlVIXuB2rb5Y7oZSaBlT1sqGDUmq+UuqoUmq5UqpbiLbHKaWGK6U2K6UOKaW+UUpVNo85XB6DlVLbTXufdCtbRin1iVLqiFJqrVLqUaXUTvPYZ0Bd4BfzaeVRt8veGOB87ZRSS5RSx5VS+5RSrwcxPQf4EbjeLBsPXAt84Xa+hsDdwECt9QytdbbWOlNr/YXWelQon49gDUTAhcLSHtiCIawjgB8cQujF88BUoBJQG3gHwMz7G/A2UAV4HfhNKVXFLPclsNQ8//MYrU3MsmeaZV8AKgMPA98rpdJCsPs+4AqgK1ALOAK865XnQqAx0BN4RinVxEwfAaQDZwG9gEGOAlrrm4DtGE8tZbXWr4RwvreAt7TW5YGzgW/ysf1T4GZzuw+wGtjtdrwnsFNrvSif8wgWRwRcCIUfzRau43W727H9wJta61yt9dfAeozHdG9ygXpALa11ltZ6rpneF9iotf5Ma52ntf4KWAdcrpSqC5wPPG22ImcDv7idcxAwWWs9WWtt11pPA5YAl4ZQp/8CT2qtd2qts4GRwNVeHY3Paq1Pa62XA8uBlmb6tcD/tNZHtNY7MW4+oRDofLlAA6VUVa31Sa3138FOorWeD1RWSjXGEPJPvbJUAfaEaJNgYUTAhVC4Qmtd0e31f27HdmnPiGjbMFq03jwKKGCRUmq1UuoWM72WWcadbcCZ5rEjWutTXscc1AOucb+5YLRya4ZQp3rAJLdyawEbUN0tz1637UygrJvNO9yOuW8HI9D5bgUaAetMF9JlIZzrM+AeoDswyevYIUL7DASLIwIuFJYzlVLKbb8uno/zAGit92qtb9da18Jo/b6nlGpg5q3nlb0usAujFVlJKZXqdczBDuAzr5tLaoh+3h3AJV5lU7TWu0IouwfDDeSgjtfxsEJ8aq03aq0HAtWAl4HvvOrsj8+AuzCeQDK9jk0Haiul2oZjh2A9RMCFwlINuE8plaiUugZoAkz2zqSUukYp5RC9IxgiZzPzNlJK3aCUSlBKXQc0BX7VWm/DcIk8q5RKUkpdCFzudtrPMVwtfZRS8UqpFHOonbu4BuID4EWlVD3TvjSlVP8Q6/wN8LhSqpLph7/H6/g+DP94SCilBiml0rTWduComWwLVkZrvRXDf/+kn2MbgfeAr8zPI8n8bK5XSg0P1S4h9hEBF0LBMaLC8XJ/ZF8INAQOAi8CV7sNb3PnfGChUuok8DMwTGu91cx7GfAQxqP/o8BlWuuDZrkbMDpKD2N0Hjr9vVrrHUB/4AmM4XU7gEcI7Xf9lmnHVKXUCeBv8zqh8BywE9gK/Al8B2S7HX8JeMp0zzwcwvkuBlabn81bwPVa66z8Cmmt52qtfZ52TO4DxmB0zB4FNmMMI/wlQH7BgihZ0EEoKEqpIcBtWusLo21LNFFK3Ykhul2jbYtQupAWuCCEiVKqplKqkzmWvDHG04N3R6IgFDkyE1MQwicJ+BCoj+GemIjhcxaEYkVcKIIgCBZFXCiCIAgWpVhdKFWrVtXp6enFeUlBEATLs3Tp0oNaa58QEcUq4Onp6SxZsqQ4LykIgmB5lFLes5UBcaEIgiBYFhFwQRAEiyICLgiCYFFkHLggCBEhNzeXnTt3kpWVbxQAIQApKSnUrl2bxMTEkPKLgAuCEBF27txJuXLlSE9PxzNApRAKWmsOHTrEzp07qV+/fkhlxIUiCEJEyMrKokqVKiLeBUQpRZUqVcJ6ghEBFwQhYoh4F45wPz8R8BjDbtd8s2QHuTZ7tE0RBCHGEQGPMX5YtotHv1vB2Nlbom2KIJR4JkyYwD33GOtxfPDBB3z6qffyorGNdGLGGEczcwA4dDInypYIQslCa43Wmrg4/+3WO+64IyLXsdlsxMfHR+Rc+SEt8BjDERxSXImCED6vv/465557Lueeey5vvvkmGRkZNGnShLvuuos2bdqwY8cOxo8fT6NGjejatSvz5s1zlh05ciSjR48GoFu3bjz22GO0a9eORo0aMWfOHAAyMjLo3Lkzbdq0oU2bNsyfPx+AWbNm0b17d2644QaaN2/O008/zVtvveU895NPPsnbb78d8fpKCzxGEf0WrMyzv6xmze7jET1n01rlGXF5s4DHly5dyvjx41m4cCFaa9q3b0/Xrl1Zv34948eP57333mPPnj2MGDGCpUuXUqFCBbp3707r1q39ni8vL49FixYxefJknn32Wf7880+qVavGtGnTSElJYePGjQwcONAZ32nRokWsWrWK+vXrk5GRwZVXXsmwYcOw2+1MnDiRRYsWRfTzABHwmEOHt6C5IAgmc+fOZcCAAaSmpgJw5ZVXMmfOHOrVq0eHDh0AWLhwId26dSMtzQjsd91117Fhwwa/57vyyisBOO+888jIyACMyUr33HMP//77L/Hx8R5l27Vr5xy/nZ6eTpUqVVi2bBn79u2jdevWVKlSJeJ1FgGPUcSFIliZYC3loiLQ4jQOQXcQ6lC95ORkAOLj48nLywPgjTfeoHr16ixfvhy73U5KSkrA69x2221MmDCBvXv3csstt4Rcj3AQH3iMIQskCULB6NKlCz/++COZmZmcOnWKSZMm0blzZ4887du3Z9asWRw6dIjc3Fy+/fbbsK5x7NgxatasSVxcHJ999hk2my1g3gEDBvD777+zePFi+vTpU6A65Ye0wGMMh37LhAhBCI82bdowZMgQ2rVrBxgt4EqVKnnkqVmzJiNHjqRjx47UrFmTNm3aBBVhb+666y6uuuoqvv32W7p37+7T6nYnKSmJ7t27U7FixSIblVKsa2K2bdtWy4IOwfngr82MmrKO/3Y5i8cvbRJtcwQhZNauXUuTJvKbdWC322nTpg3ffvstDRs2DLmcv89RKbVUa93WO6+4UGIMcaEIgvVZs2YNDRo0oGfPnmGJd7iICyVWEQ+KIFiWpk2bsmVL0c+mlhZ4jCHDCAVBCBUR8BggffhvPDFpJeA2E1Oa4IIg5IMIeIzw5cLtHvsyCEUQhPwQARcEQbAoIuAxijTABaF4uO2221izZk3QPEOGDOG7777zSc/IyODLL78M+5qBzhcuIuAxRnGOyxcEAcaNG0fTpk0LVLagAh4pRMBjFPGBC0J4vPLKK86QrQ888AA9evQAYPr06QwaNIipU6fSsWNH2rRpwzXXXMPJkycBI3SsY4LhRx99RKNGjejWrRu33367c7EHgNmzZ3PBBRdw1llnOVvPw4cPZ86cObRq1Yo33ngDm83GI488wvnnn0+LFi348MMPAaNhds8999C0aVP69u3L/v37I1JnGQceY0gDXCgRTBkOe1dG9pw1msMlowIe7tKlC6+99hr33XcfS5YsITs7m9zcXObOnUvz5s154YUX+PPPP0lNTeXll1/m9ddf55lnnnGW3717N88//zz//PMP5cqVo0ePHrRs2dJ5fM+ePcydO5d169bRr18/rr76akaNGsXo0aP59ddfARg7diwVKlRg8eLFZGdn06lTJ3r37s2yZctYv349K1euZN++fTRt2jQiAa5KjIB/tWg7FcskcknzmtE2pVA4Y6GIF1wQwuK8885j6dKlnDhxguTkZNq0acOSJUuYM2cO/fr1Y82aNXTq1AmAnJwcOnbs6FF+0aJFdO3alcqVKwNwzTXXeISLveKKK4iLi6Np06bs27fPrw1Tp05lxYoVzhb6sWPH2LhxI7Nnz2bgwIHEx8dTq1Yt59NBYSkxAv74D8bdPmNU3yhbEhnEhSJYmiAt5aIiMTGR9PR0xo8fzwUXXECLFi2YOXMmmzdvpn79+vTq1YuvvvoqYPn8+p8c4WWD5dVa88477/hEH5w8eXKRBKgTH3iMIS4UQSg4Xbp0YfTo0XTp0oXOnTvzwQcf0KpVKzp06MC8efPYtGkTAJmZmT4LObRr146//vqLI0eOkJeXx/fff5/v9cqVK8eJEyec+3369OH9998nNzcXgA0bNnDq1Cm6dOnCxIkTsdls7Nmzh5kzZ0akviWmBV7SkAa4IIRP586defHFF+nYsSOpqamkpKTQuXNn0tLSmDBhAgMHDiQ7OxuAF154gUaNGjnLnnnmmTzxxBO0b9+eWrVq0bRpUypUqBD0ei1atCAhIYGWLVsyZMgQhg0bRkZGBm3atEFrTVpaGj/++CMDBgxgxowZNG/e3LkeZyQIScCVUhnACcAG5Gmt2yqlKgNfA+lABnCt1vpIRKwqxUgsFEEoOD179nS2fgGPVnaPHj1YvHixT5lZs2Y5t2+44QaGDh1KXl4eAwYMoHfv3gBMmDDBo4xjBEtiYiLTp0/3OPa///2P//3vfz7XGTNmTNj1yY9wXCjdtdat3GLSDgema60bAtPNfaGQaNeKDlG1QxBKIyNHjqRVq1ace+651K9fnyuuuCLaJgWlMC6U/kA3c/sTYBbwWCHtEUxEvgWh+Bk9enS0TQiLUFvgGpiqlFqqlBpqplXXWu8BMN+r+SuolBqqlFqilFpy4MCBwlscQex2zYx1+2Jq9mPsWCII4RNL/yUrEu7nF6qAd9JatwEuAe5WSnUJw6CxWuu2Wuu2aWlpYRlX1EyYn8EtE5bwy4o90TbFB/GgCFYjJSWFQ4cOiYgXEK01hw4d8ljpPj9CcqForXeb7/uVUpOAdsA+pVRNrfUepVRNIDJzQ4uRXUdPA7DvWFaULREE61O7dm127txJrD1pW4mUlBRq164dcv58BVwplQrEaa1PmNu9geeAn4HBwCjz/acCWRxF4sxWbkyN/DBbLzITU7AaiYmJ1K9fP9pmlCpCaYFXByaZs4gSgC+11r8rpRYD3yilbgW2A9cUnZlFQ5zpp7DHkn6b7+JCEQQhP/IVcK31FqCln/RDQM+iMCqSDBq3kAMnsvnjAT9ue0cLvBgF3GbXrN59jOZnVvA7tVbch4IghEqJn0o/d9NB1u874feYw01RnC6UrxfvoN+YeczddDBovimr9rLlwMliskoQBCtS4gU8GHFRaIGv3HUUgO2HM/0ed9xM1u45To/X/io2uwRBsB6lWsAdHgx7LDnBBUEQQqR0C7jThRI7iA9cEIRQKdUC7nCh2KOgmoGGCYp+C4IQKqVawB0+lOLUb2lhC4IQKUq1gDvawLGkqSLwgiCESukWcOnEFATBwpRqAT9wwliZY8zMTcV+7UAzLWNqWr8gCDFNqRbwY6dz889U3Hjp95KMwzzz06ro2CIIQkxTqgU8KT761X/w63+DHr/6gwV8umCbhOgUBMGH6CtYFPEXi6So8dbhH5bt8jweoJy46QVB8KZUC3g0/c3h3jpsouCCIHhRqgXcCqgoTjYSBCG2EQGPMbx93a6Y5SLggiB4IgJezDjcNjatOZ7lOwrGW6cd0/3FhSIIgjci4F7MXL/fr7BGmicnraLFyKk+6d4y7YiZIvotCII3pVvAvURx77Es/jN+McO+WhYde4IhAi4IghelWsC7Nk4DoFmt8gBk5doA2HLwVNRsCoTM0BQEwZtSLeDJCUb1a1cqA7hGfESzv3DXkdMe+w7hlj5MQRC8KdUC7o3L31x0apnfqX9fvTes/IIglF5EwN2IwsTMkBEdFwTBGxFwfFu5sdjqlVgogiB4U8oF3LPJ7fKBx55Yxp5FgiBEm1Iu4J4UVXCrTftPsuNwZqHOEYP3FEEQokypEfBQWtXBllhbtesYn8zPKNC1L3r9Lzq/MrNAZR28O3MTW2NweKMgCNGjFAl4/nmCBY667J25jPh5deHtKGC5CfMzuH7sgkJfXxCEkkPIAq6UildKLVNK/WruV1ZKTVNKbTTfKxWdmUWLVbwTRzMLN8X/0Mls/tpwIELWCIIQbcJpgQ8D1rrtDwema60bAtPN/ZglHJFWYUfrLh6y8+yFKn/juIUM/ngRubbCnUcQhNggJAFXStUG+gLj3JL7A5+Y258AV0TWtMgSKyNLorkO56b9JwHpEBWEkkKoLfA3gUcB96Zbda31HgDzvZq/gkqpoUqpJUqpJQcORO/x3Z9meQ86KQ5hm7ZmX1j5i8IkiasiCCWDfAVcKXUZsF9rvbQgF9Baj9Vat9Vat01LSyvIKSJCMHGOpRbp2WmpRX4Nu3hQBKFEEEoLvBPQTymVAUwEeiilPgf2KaVqApjv+4vMyghw9HROtE0IiTJJ8UV2bvdRNhkHT3HoZHaRXUsQhKInXwHXWj+uta6ttU4HrgdmaK0HAT8Dg81sg4GfiszKCHDghK9Y+UyhN99jOSZKJLBrTbfRs+j08oxomyIIQiEozDjwUUAvpdRGoJe5HxX2HDudb57yKYn55omVjs6ixrG6T1au+FIEwcokhJNZaz0LmGVuHwJ6Rt6k8Plx2e5omxARjmbmsGrX8SK/jl3WZxOEEkFYAh6rhDKqIviiwJ6LJkTSg+IYuhcKN45bGMEru8g4eIoflu2Kqc5aQRAKT4kQ8FDI8yvgRa9o4Ux/X727aFrft0xY7LFMnOi4IJQMSk0slKJcZScYseBn9p7BWVp8/YJQ0ik1Ah7chWJQWF07ciqHB77+l1PZeW7njD2xjD2LBEEoCCVCwEPRyJAE3JS2gsYFf2v6RiYt28U3S3a4rltIAY/FG4AgCLFBiRDwUPAn4EWlje6XioVZj9EIGSAIQtFTagQ8FB94YYUtzlRK91ZztHzv7vgIuDhRBKFEUGoEPBgOjS2srMWZQuk+4qWwLhRBEIRAiIBHkGU7jgLw9vSNzrTC6nck5N8nvrncUwShRFBqBDyUUeCF7TDcdzwLgMwcm9/jt3+6pFDnjxSi34JQMig1Ah4KhQ1m1aBaWQAS4/2fINxY4JHCuz6x4JcXBKHwlAgBP3IqNkLF9mpaHYCrz6sdZUuC4z0iZ9P+k7w2db0MWRQEi1EiptKHslZk0AUdQsgTCg5fc7R1cO+xLKqWTSIh3v/9eaNbfJb04b9RLiWBE1l53NwxnbRyycVlpiAIhaREtMALOizOV2gLp7wOV0U0BfzwqRw6vDSdF35zrT/t7dD5bcUej/0TWXkIgmA9SoSAF5YZ6zwXEyqoDzzObcWbSBHuqRyLJs9c76qT98zSSct2+S17/9fL2Hwg9OiJgiBEl1Ik4EU/kcchlNEMt+0u1Z8tyCB9+G9sdYtECIHDCszbdIiHv11edMYJghBRLC3gC7ccYv6mgxFzWYRyGrtdM27OFo+AVQ4c4hkrMx0/npcRdhlZ7EEQrIOlBfy6sX9zw7iFIcvlmt3HueydOX7FN1T+XLuPF35by4uT1/occ02lL/DpI4bWLpdOOMjMUUGwDpYW8HDQGl6aspZVu46zOOOwkeYl/aFol2PEi8PX7E6c+WkW5TjrPcdOB13lp7ALMttiIPiWIAihUSKGEYZKfmFineFkgyyq5hpp4ivSxTGMsONLxkryGaP6Bs1n1CV8NZex4IJgHSzXAv/p3110fGl6SPG9A1EYiQom0k5xL8T5C0uwm08oFOZzFQSheLFcC/yJH1ZyKsfG6Vz/8UYCoYHZGw64dvzlCUG7VJChgq5RKNYVQfGBC4J1sFwLvKD8uny3T5q7Vj3+w0oyc4zOze2HM/lo7lbnsRNZLn+38lPW+9jpHBu3TljM/ROXFdbsAqN1YJfRmRXLBCwno1AEwTpYrgXuj1AajQfd4qU4fN3uxb5atN1jdMrzv67h1gvrA5DjNlXfoYm5br192Xk2Dp3McZ7Pe2JQcVLoTkxpgQuCZbBcC/yUGap18so9+eT0wk2XnAs4eIlVIPFyT3XNdDzgTHvom+VcMGoGeRYZwhHMxSP6LQjWwXIC7mDD3hNue/mrjrtoBRKpQCMw3JNnuQm3A0eY2Dxb7Kif1oHHoAQT8MK24AVBKD4sK+BlkuILVf7iN2czbOK/HmmBFiB2F/Ypq/YC0LZeJWdasI7N4mJJxmHSh//G6t3H8s0rrWxBKBlYVsCTE8Iz3V20NLDOowXvSM/fheIvzTm0MCyLIsu0tcZTwOyNB/PNa+VRMoIguMhXBZVSKUqpRUqp5Uqp1UqpZ830ykqpaUqpjeZ7pfzOFUnym5Tjze+r9zq3A/mqAw3A8Kd3/twt0dRF1/j0og/aJQhCbBBKMzYb6KG1bgm0Ai5WSnUAhgPTtdYNgenmflQIV5Du/OIfv+mBhtDtP5Hle01/dsRAECv3zyLQPU5a4IJQMsh3GKE2mnSO4BuJ5ksD/YFuZvonwCzgsYhbGNgut+3InDOQsPUbMy9oOZcPPDJ2hMORUzl8OHuL03bH+66jpwOWkaHeglAyCGkcuFIqHlgKNADe1VovVEpV11rvAdBa71FKVQtQdigwFKBu3bqRsdqL3AgN3wtH2Pxp/XE/Aa6KmhE/r+bn5btpaC6oHEodgrlZCjsVXxCE4iOknkCttU1r3QqoDbRTSp0b6gW01mO11m211m3T0tIKamdQfgiwwky4FNS14JC8V/9YHxE7wsERUsBheSh1OC5LqAlCiSCsoRxa66MYrpKLgX1KqZoA5nv0ph9GiHD022MUShQHTztsdsb+FveIIJQaQhmFkqaUqmhulwEuAtYBPwODzWyDgZ+Kysji4uDJ7NAzx0hHoMMdsmGf0U0hHZSCUHoIpQVeE5iplFoBLAamaa1/BUYBvZRSG4Fe5n7UmW6Ohy4I/saGByJWZNLbjlixSxCEoieUUSgrgNZ+0g8BPYvCqMJw6ydL8l3sINJEs9vPu8UtDXBBKD1YNhphtIXKcf3mI/7gRCHW2CwoWbk2znn6d590caEIQunBslPpoy1Tjkk70RBvgG+X7vSbLvotCKUHywp4KKzdczzaJhQZ2w+d8pte2Ba4RCMUBOtgWQEPRafem7W56A2JEoGGLooLRRBKD9YV8DBjgJcWZJq8IJQerCvgIQhVUa7vGKv3BlnTUhBKD9YdhRJCHlshxWzN7uMRi7MSaQK5qvNEwAWh1GBZAQ+FwmrZpW/PiYwhRYGEihWEUo9lXSih8GchZmXmx/bDmUV27sJQ2HU5ZRCKIFgH6wp4lFuaJ6Ic0W/Kyr1+023SAheEUoNlBfzQqZxomxDS8mVFRaAngEVbDxezJYIgRAvLCvikCMUALwzSXygIQjSxrIDHgq82mi1wQRAEywp4LCDyLQhCNBEBLwS7jgReONiqRHN1IUEQwkMEvBB0Gz0r2ib4UDk1KdomCIJQTFhWwIO1FA+cyCZ9+G/FaE3sEB8nLWhBKC1YVsCD8e+Oo9E2IWpIv6oglB5KpICX5unkMjJGEEoPlhXwYI6CD/8quXHA86M037wEobRhWQGvUjZwZ90/22PbhXJzx3pFdm6ZXCQIpQfLCnjGodgMJhUKRdnNKPHABaH0YFkBtzK7jmYFPPafTumFOndhF1mWMSyCYB1EwKPAlgMno22CIAglAMsJeM0KKdE2QRAEISawnICXCIL4KWQQiSAIoSICHg1EpAVBiAAi4FEg2Ko5/+16VjFaIgiClclXwJVSdZRSM5VSa5VSq5VSw8z0ykqpaUqpjeZ7paI3t2SwLcgQyEpnRDkYlQxDEQTLEEoLPA94SGvdBOgA3K2UagoMB6ZrrRsC0839Ikd8xIIgCAb5CrjWeo/W+h9z+wSwFjgT6A98Ymb7BLiiqIwUihG5QQqCZQjLB66USgdaAwuB6lrrPWCIPFAtQJmhSqklSqklBw4cKJy1JYiWdSr6TZcnDEEQQiVkAVdKlQW+B+7XWh8PtZzWeqzWuq3Wum1aWlpBbCyRNKpW1m96ckJ0+5Xl/iEI1iEktVBKJWKI9xda6x/M5H1KqZrm8ZrA/qIx0RNdQiTGX8iSF644lzhZkEEQhBAJZRSKAj4C1mqtX3c79DMw2NweDPwUefNKDmckxXvs+4vbHQu3JoknLgjWIZQWeCfgJqCHUupf83UpMAropZTaCPQy94UAeLerh13UMCp25IfItyBYh4T8Mmit5xJ4dHDPyJpTcnFfwzM+TlGvSmrAvOP/cz6j/1jP6t0hdzVEDGmAC4J1kJmYxYT7HTAhHz9398bVGND6zKI1yIuOZ1Up1usJglB4LCfgll2vwE2z8xNwiN7q8iWlk1gQSgOWE3CrdrJ5tMDjA3zsbnUrTgGf8VDXYruWIAiRw4ICHm0LCkYZt1EoT17aJN/8B0/mFKU5HpyV5hqTbtXPVxBKI9YT8GgbUEC+vL2Dc7tfq1r55v947taIXj/VaxijN44+VhFwQbAOlhLwrMyTDMqaSCKFW/cxGpydVpbB5mr0gXzg7tppi5Cz/5JzawDkO0FIhFsQrIelBHzZxGd5MPE7BsVPi7YpIfHLPRd67I+4vBnrnr84sA/cjXt6NIiIDVXLJgPR6xQVBKHoyHcceEyRa8TRTiY3yoaERnKip1DHxSlS4gK7MtxbwY2ql4uoLfEquIC7XCjSFBcEq2CpFrjVqF4+tAWYr/Qz5jvSQqryEXBBEKyHCHgRUqFMYkj5yqYU3YOQY1x3KGPPjfyCIFgFSwp4aWhLRkpIHQ35UH3g4kERBOtgMQG3mGlw1YsAACAASURBVLmFINJCGld6PjpBKDVYqxPTgjxx6Tk0q1UhpLyefu/IKnhciD5wmUovCNbB8u2yPs2qR9uEoAztcjadGlT1e6x+VSMiYXG4hPIbhSIIgvWwmIDbAVAlpJU4ZVhnVo7s7dx3r1V2nj0i17ixfT3iFFzUNPiNLs/m6OyMQ2stwwkFwQJYRsAX/N/9dNzzOQC5BJ8WbhVSEuMpl5Lod4jf6RxbRK7RtFZ5trzUl9qVygTNl2s3bhjHT+dS//HJfL5we0SuLwhC0WEJAV829XM67hrv3M8toa5790avYyb99efXCZi/Td2K/HrvhQGPu5PfOPBcmyHgJ7KNMAXfLd0Z0nkFQYgelhDw7IMZHvv2KAwkrBHipJxIYTPVPFgMkyf7NqFWRVfL+j+d0gPmzW8UocOF4kRcKIIQ81hCwL05S+2JtglFjsMHHbzzUXmM71ZBbmz5jUJpXbeix75lF84QhFKENQT82A6P3SEJU0Mqdm+EAkKBK1ZIcdHBXOLskuY1guZzb1kHs9G7BV422dMNNbJfMwAqpyYBUPGM0GaRCoIQPSwh4B32TSxQuZa1K+afKUZpVL0cGaP6csHZ/ocgGmiPlnWwe4x7voxRfUlJ9OwITk6IJ73KGc6Wf55Ns/dYVkFMFwShmLCEgBeUSLaawz1VQVqwBfFapLq1pN3rO+aG1sx8uJtz3yHgfZvXBCDgqm7m+4Ith+jw0nROZlsv9roglBZEwIuIt65vHXLeSNnpPtKkd9MazolC4BplsvPoaQAe7t3Yb3m7l/N73/Espq/dx2tT10fGSEEQIkYJF/DoKXhifPjXDnfyjHd29yt6X3/upoMALN9xFIBr2vofnuhtwZFTOdz6yRLembEpLNsEQSh6SraAR/Jc5s2gatmkCJ7VPHcBLXUfQmieyLXpdfNKTsh/8pMCHwU/IS4UoYAcz8pl3JwtARsmxzJz+WjuVpn1WwhKtICHGsDJKnRvnObcfqRPYx8BD3YjSEooWDzw7NzIzAgVSh/P/bKGF35by18bDvg9PvKX1Tz/6xrmbz5UzJaVHCwv4MFu3iVMv3njulbObX+dpAu3HuKMAKvP+3MnfXpLOz4YdJ5bJllSzarM23QwYgthR4rjp42lD7Ny/cf1cXSQn8iyxhKJsUi+Aq6U+lgptV8ptcotrbJSappSaqP5XqlozSwYBXVNBKMo9C2/G81fj3RjzqPdPerjz45l248y65FuTH2gi88xfzMxuzRK4+JzPceZe2uA+3VW7z4GwM4jmTz3yxpyIhRwSygcizMOc+O4hbz554Zom+JBfuusOlaJssnPqMCE0gKfAFzslTYcmK61bghMN/djjkguxH7gZDYAh07l8N0dHfPNn5wQuYebelVSqVP5DI9FGQK1tKuVS/G7IHIo7iR/OdwF/aFvlgPwzvRNfDxvK/M3H8z3nIXljWkbGDRuYcDjO49kkj78N9bvPRGxax47nUteEFV5fdoGbhz3d8SuV1gyzcBn/5od1LGCo8ERqM3j+E3aC9Mqmj0aPuqdf74SSr4qo7WeDRz2Su4PfGJufwJcEWG7PMjRBQxeFUEBd29tBhvd0r1xGiMvb0qbupF/KCmXksjz/ZtxS6f69G/luxByMEL9KIIt6LDl4CnAEDhwCceOw5ks3eb9E4kMb03f6BxB449J/+wCoM+bsyNyPa01LZ+dyqPfrQiY5+3pG5m3yctve2wnbJtfeAOOboft4d0cHN9trHm/XC3w4McLJeAznocdgW/w+bJvNexbY2xrDasngd06/T4FbSZW11rvATDfqwXKqJQaqpRaopRacuCA/86M/Fhae1CByhVXJ+agDnWd2xXKJDKkU/0iG8J4U8d0nrm8achrXDoIxR6llM+fLZQVejq/MpOr3l8Qlj2RIjPCnayOOOw/LNsVXsEx58P4SwpvwJst4OM+BSoaa6spOQU8gF2O33BUbzzvXwDvm0/UK76Bb4fA3+9H0aDwKPJOTK31WK11W61127S0tPwL+D9J4EPm+/P9m3mkl+ckiVlHCna9fKi17HWWJ9/m3H/gokYROW9YP+RdS2FkBTgY2vjs5MTQvmofAfezyluq7QjlyEQBWW4C+tO/u0gf/lu+szdPZOVy0HRJBWLX0dNk5/mK86nsPPafcE3xzw7QQVZQHHHYkwJNVQ1EbmaELAhfzZSCRPKomrcvQjYA4/vCl9eHX+7bIfB/PQy7CC7QjgZWgTpfbblwZJtz96zhv7BxXyHdaCd2G+8nC/k5nj4CmUXzROpNQQV8n1KqJoD5vj9yJvkhBGXzbmGuSBnKed+cx8Vxi/zm7xS3kv8l/F+BzKn579tUUK4/bJWyyVzUpLpfO0LBUSIh7zgs+zy0Qiu+Nd5/vZ86yvjBBWuU14o7Rr+4+Vx9Xu2gdni3lvx98q9lXMWi5LtQCm7/dIkz/X+T1wKGXxpg9oYDbNrv9qc6vJVjy36i+ciptH3hT9btPc48P+4Rm13TadQMHvj6X59jV7w7j3YvTnfup5VLDlifguDo68iJdM/awY2w6vvQv98wUCieTRjPW3tvhqzjQfPa7Jor35vHgRPBb6Bsmwsbpjh3tdZ8vXg7p/KbF7B6ktG4MAwDYOmKFRxY+G1+1QiPP56Et1o4dxPJY+qaQgrvAXO2cXwi2Xk2vli4zWdmcijol+vDK/ULZ0uIFFTAfwYGm9uDgZ8iY45/lM7/MdlxN/8g8Q0yUm5wpn+Q9Kbf/F8kvcQNCTOJp+CP4ArXn/ySc2tQnpPctmM4nPS6n819A5Z+QiAcmt9l3Yvw092wc2n+F48zOzEz5jA96REAnurbNGD2i9Y/w9tJY0hPDN7RFexemWu3c+fnhm1lVA4Acza6BNjhG99x2Jiuf/PHi7jo9dn0ecP0T7/XkQo/3ezMf/Gbc7hx3ELenr7R4zqZOYZI/LF6H33j/ubBhG+cxzbuP+mRt37VMwBol14ZFv0fzHjRx+4TWbncOmFxSMG5HCEHqpfP/8bgd3SFl//0s7+3MW7OFhjTFr67xeP7XbP7OPd9sdjoMF32Bcx+1f3k+V7feUmt6RZvdDCTFfz7HT11Pf9sP8r5L/7JkPGL2Hc8tIBlC7ce5rHvV9JsxB8e9f6/2Vv4YqHZEp76lEcZR3vi7k1DSZtym0+dnL57891m16EL5ta/PHbjsBd+2PDyr5yb70zfxJOTVvHLit2hlbW5bmzOJR9zThlPMW5PCpEmlGGEXwELgMZKqZ1KqVuBUUAvpdRGoJe5X3T4FXDjQ3K2XpWNjJQbuDh+cVinXpY81Lk9MH46ibi+iDSOUJPAkwyWJN/pYc0PSSNpdnIBTH8Odi8zHqMOboI/R8Iv9wW1I4lczjxsdl7l+HkUtOXBbt8WKUCSMmy+rEVN34Mv1YHPrqRmnOFOGnKeV+fqp/3hlbMg6zh17Tt9Wtzuf1atYcqqvW5HPf8xjvG+o6ashYObKI8htusdj7Z5p/3a//o0c/hb9knYv87ph45T8G7S29yX8KPhLvrjSeYm38ekpGecf/Rcx0IUCpj8MMx+BUZW4KYnXuLvLcZ39+uKPUxft9/vMLsVO49iP3UEDm0GXI/zCXH5t23y7NoQ7M0z3BI9W7ZP/7iKF35b61kw5yTHMnN54J0veHXDxexbNhl+ugtmvODKYwsyNvrgRsg6xrUfLOD8F//EprXrm/jqBng+sKuysdsIpVnrD/DuzE3YXzmbNc+04N73JgUsd9rNVebuIntx8lo+/XEy5J6G+e8401ftOub8LNPUMbNOOYHrNLoxG0ZdyN1f/hM4jztJZT12E/DzxJSbBSMrkDnzddKH/0b68N84HsqY8zmvof79AnB11Afl4Eb4X01Y/7tHsl4/xXiKcXtSiDShjEIZqLWuqbVO1FrX1lp/pLU+pLXuqbVuaL4XrcNH+345jyVM5Gy1i/YnpgGQlFcw/1d5dZq2ah0rkm/lpcSP+Df5duexxSl3syDlXgC/rocqyvOadU1XBgc3wthuxmPUmPN8yjnZuwpWfgfA8wnjSckzH3/99YJPfxbGdoXJRmvbX3Mj0Z/fNvs4bJ5OnPnnKZvoVW7LLMg8BG+cy0cn7wo4ZjcOO68kfMjN8X8Ero9JfJyCMefxe7JrdGmGOYLFcS5vbHYNX1wN77VnboCZeywYQ211kNZxm5yCkme3cwZZ9D/hGXL4ivi5TF65x2nP2WoX125/Fv6vp3En2rearTPG02/MPE6+cwG80wYObabC2q98LsuRDFj8EexcAmt/cSbn5Nnhr1fgswFuFcnHNQGg7Xw15kleThxLssqj3NYpvnmCnWdMWxh3EYsyDnPgRDZ2u6amMv+C+1aCLYcZ6/axaKvrb/nH6r38s/0IcXGKfnHzOUcZa55qDXGZB2kat4139g/xvda2+bBxmseAAPfVm8pzkj+ShxtPFm5c9s5cr5s9kBektX9yL01yVrnK2O3888XT7N4XwDubUt5jNw67a57E2l9h6tMc/HYYAGf89Sxzk+9DYSdz4WcuV4kbxzI9hf2yU98DcDTTj+Db7fDeBbDN7LjfvQxsOeyb96lHNluem7upiHzillhcUvkRtDsTfuHOhF/gAHyY+g0XVgzcYXkGWWSRhN28X90d/6PH8e+Sn3Nup6pskvD90gwB1Hi3Oi+JWwgT3ofmH/CL/QKuip8DqcFieJtoDR90MurX7m/ax7m10ux5kJMJKg5yTsKrZ7uOLRoLnR/ysQMgwTuA1ne3uLaPZLjOfXw3fHI5DHQTvWyjlTQ64T0ezL2LRPKwEecc4vVSwjiuTfiLa3E9utpsnv7QcskJVMvZxpc57wFQS7l+tHuPZ5FubieRSxaeLoqvZv3LoO3GH+Khb/4B4v0KvYOsXBupyQnYcnMYnvAVN56c5nG8PJlk59rJyrVR9fhqpic/AscwXjuXwEcXUR+YmnQm5bPMx+T3O1Ev7zTwpfM8OXl2Ej++BHXC9SidwniySKbrq7OYX/cfPKLjLHjXGAZoy0GnnQP4GVFyaBN3ZH7oaj75aaDYJ95E3A0TDSFPqWA8gaR3ZnTN13gY4OAGKnCSU6Rg8+OvX/jZCD60Xc69PRpw7HQuny4wHuPfur4VbyeNASA960ufae7ZJw6SNOFi16/LHFmTd53r6cW9f8DRus7cvIAzvGxIItdjAfKM7dv57y8H+OauzlQoY8wkLksmp3M8f0cnsnJ5bvSrvJr3Nns2TYQ6DTg84AvavLyAdumV+eaOjsZ/w40EbLz8+zquaVODql/fCID7v7C2OsjlcX9TY+YYmAn0eg6mPeP6vBeN9TjfafNbffn3ddzZzfz/2W1k5eQw5aeJDNi/GsZfTO7TRzh2IouqwN9bj9Df7RzxUx507fwyDK77jEhjjan0+fjAF6V/SNVv+gU8viblFn5OeoqWahOVOM4jid8EzAuwIWUwG1IGO/c7xq3mlXUX8ViC78IS7ye9BRlz0O43mbgQ7ouLxzk361dNJT3OrQNm8iPGI9mL1T3F28HbbXx+wODnsX/V975lj243Jj8c2mS05Ly4Mn4uABtTbuaTxFEkZR2iudrCdQmzfPL2ndTMox/grJx1TEx6nqqntzrTWquNNFHbSD7lWgava9wKksmhjdpAeYyW+arprs69BLNfYmWCy1/uzXO/riE7z8bVk1tzc8I0n+O94v9hzdK/aP30j3SZfYPHsW//cYlxozi34YKmi8dx45i/+SCNnpriId4A61L+A8DBk9kkbfFaHWr2q5AxB3YsRP3zCcPiv+c/8V4t7MkPe+za7b4CHLd1pvH9j6oL/5h//Iw5jJnpGnW0PGUom1JuZt66HT7lH080niTembGJTxdsozynOE+t93BDt1Nr2X7Yc/TMoy+9hjrk2ScB8LZbNMqT2XnMNoX/9yTjKWv/Kc//aBpH2ZAymCcSXDfD9C8v5LljjzNv00H2n8hi/a4DrEi+ncO/PetRdknGEU5nGnbV1Pth+3wqv1Wf2mo/h7etMH3Kno0Vx3eW9EHgSXaN47a7dtzEG6DSrCc89pPJ5Ty1niqprttz3mdXkzKqBj8ud/2WGz45hRd/M8aRd45bwRG30VUqx/XUmV/fREGxRAu8Uqf/wM8/Bs6weXrgYybnxmXwU/IzbLVXD/v6XyUZHWN3JvzC23kD/OZpsPULtjj3gnTEZJ+E9zp4LBN3fctKMNktz9F8Oj1yT8E/n/okJ4Uy+/ObwKLooFecMbKkc/wqsmZeQd/kwI9/PyY9w1U5I3kk4Wv+m/Cbz/FJySOMDbd7yYdJb3jkSc/60uOpJ5E8qnKMJBX4xt1s1atctuV6fKXbReu4jQyN+9V5Q3BQfsnbECQ4YwI2dh09zTPjvufOeP8+2aYqgxSC+HRNHkj0cxP1ouK6fFacWha85Vbl33f9/pPvjP+Z9239SFd7mJX8EAA/5V7uPP5N8vNcWulXcHt4DdQPuHzHEefRnq8ZT2GP9GnM3eZ35NEAARan3AXA7QmTPdLbx61j2qzn6berA4kqj7hkzbCEH5zHO8StoezqdX5taKq2MTbpDXjrUWjoOfvylcSx/Cf3McpnBv7v3J3wc8Bj3jSJ28H3yc/yT9q1cPp8KFORhK1GX8dB7XLfXB3/F3ZtfC6V1Uk2vtKaSv7+hkU02F0VZ/Citm3b6iVLluSf0R8jK0TWmCJgiu18LgnWiTp8uzHhw3uc6ZX/Bz/c7r9MqIw0O4oObYZ328Mtf8C4HoU7ZzGx2l6PZnGuP9512U9zgArMSH44SKn8eSP3qpAE1B877GnUiQs+8eyILksldTJonkhwVKdSUZ3KP2MIDKnyORMOuSbGfZAwiDvy8h/auEdXpqY6zC05D/N4wld8YevJBNvFHiO+wmGdvQ7rdR36x/ufvfps7k2MSAxy46p3oTHU0Y1V9nTOjcsokD3BON3iZo71fJUab/hv/O3WlT3chX5J7wxDfi2wDUqppVprn0dmEfCSwvVfwom9sHU2rAnytGIRptnOo1d8CMMphbDYqytRQ0Vmglv9rM/ZmlKwWdJWIz3rywLfrJw4GlkFIJCAW8KF4o5NxRMfwrjwUsfEQv64YgwR76IhUuINsDy5kE+NFmKqOdeiUOxYDHXOL/x53LBGJ6Yb8SMOQ3zkV8URBCE8yiv/4/pLIh6d3QUlJ/LuNssJOBB8QoAgCEIMcjC0Sa9hYRkB//vsYexWoY0g+cXWoYitsTjnXh1tC6LGtdlPR9sEoZRyNDf/dWnDxTIC3uGm56g1IrQVRw4k+JlSXpQ0v9Y3LTG18OetlO7abllIH3eVBsb7+bfB1R8V7lzAa7nFexM4pUMPWjXb1txv+j5dkZ3amGa+R1eOiF0Aw3Lu4qO8CISSFQrEx3ne683AlARjBNZpXTh36//lXVqo8u5sTWwYsXM5sIyAe9D+zqCH7QWpVrv/wtUfF8yevq/5plU7J3iZJv1g8C/B8xzJgDKV4YyqcOkrRlrHe6D7U/7zD/rBf3qrQXDvUrjxO7jYDFtTphI0vtS/7SbHtDG37qu87j7H4pUxcWKqzTdUwMCcJwOeMxjL7Wd57F+VbYwhvzfnHmwhfKeL7Y24Pucp7sy93+fY87mD6JX9Krupyo05j9M9+zV6Zr/K8Nzb/JwpMC/k3uiT9pP9Qp7Pu8kjbZ6tmU++YPxguzCs/P44qgvWaBgX5Oaz0B78d5zdOfKLcYV7c30uz3Nuw3O5N/HgyUFclv0Ct1YYS8/sVxmU83iBbOlw0VUh5bss+wW//wV3Vu4KHimyIFhTwC9+iVZZH7oehxt6Tlc+O96Ip6BDmRHpwJZtCBqgVRwNsj5lbF7fgNn/jmvt2kny88c503eWo5MndhvTaut3gSfzCYH50Hp4cC0kl4Mn9kDvF6DrI/6Ft3wt/+eINxdAbtjLtT1sBVz7KbS9FRr5tmAAns79D+dkjeeJvFt9jmXpJLKH7+aO3Ac8XFZv5l3JAnszpjR9lWX2Bs70u3Lu4976k33O42CLvQb9c16gSZbrJrpUN6Z11gfMK9ONJAKHMf0krxdNsj5mUM4T/G1vyinKeBx/KXcgH9ku5TjG9zTP3pwsktmsz+T5oaHFvM7UyTTOmsA4W19+LZv/n3qMzXeRqswATxEdst7hsVwjqNpmu+fTY7Ms19PSJFungNdbYGtK22zPhQhaZX3o3L4ye2TAsn/b/Uex3FqlKwNznmK6rbXf4wDJPR+HuxaylVrcnPNYwHwOlqde4Dd9Ql5vJuT15vXcq1lnr5PveRz4a2HPsLfiNCms0mcxf38SVG3EXLvnU9lXDUaHdP7m3fJ/0uye/Rqr9FkcvXw852aNY5qtDQC/NXrRY+Jg2ZTID/qzpoArxVHKsUifAxc9C1e87xHXo3vePOY1G0n2bXNcZUYeg/7vBj5nlQau0S3pnckjgb/q3AHdn4Qn9/pk7/DUDOjxNDy2DeLi+afxQ54ZOj8EdQNM63UX/MQUSPJaw/L2ma7thCTjBZB0hiuI1fl+Wo7eo3OSzbHz/uJsppQ3xFwpSDCFpWZL5+EdrR4kp3F/skhGmz+TQ/Fp0OURdjS9g4b9HiEh6QzsxDGx3rNw4QMAlEs16pZRrScDcp7jeJKxWNP5nS5i9I1ufRNDJmPrM4r+2UYcmsE246niNCkeZh6hPNMf7EqS8pxu/qetNWdnfcbo3Gt4OW8gb93UiWcGtGHIBekAXJ7tiuy3VRsLN38wqI3Px5CYYti72V6T9/K8wjG0+69z8wyVTTZJXN6yFu3/+77zBn13jivKpLtIfn7fZQDsi6/Bug6vMlH3ok/OKEbnXsM0r5baKcqQSwIv5N7InJYvc1uO8VvK1gkeN6MHcu/ysZ8RR/lf7kDuyb2XPK9RwUcpx+XZL7C64+v8o30XHbkn736G5dzFDHtrTnV4yOd4/VsnUKtSKge1+Tu6aCTUbgctrvPMWO0c+vEmG+yBY8072FDe8z/RIesdRudew7bWjzAybwhv267k4dw78j3PnhbGZ+G4IWxv/B/nsVPa9Ru69cL6dDy7ik/5s+vVZZatJY/kDkV3etDjWOOsCeQmlof7VxoJnYY5jy2zNzBuqm2NRo2++Se2auOme227ejxzdQfSb/0Eeo5gR60+3JDzFH/bm3BV9ogiWSHMmgJucn56ZbjwfkitAo0vgbKuu12nax4gsUYT1trrcuAMR0vQ6wNsdIkxO7L/u9DhbiPG9p3zUdd/yR/3d+HDIRdA10ch0bNFR/s7IC4OujwMZSoCsPYsI3bKoaQzod87UK664e5wcItXzAx3hv0L97pN2T7TV2hCwtG6BrhzAdxihrdsEjhODOCa5uv2Q61zxQia13X98Htkj+bPrj9Aj6eoc+3LXNW+AfFxit/v78zYm9o6n4KuvW4wfz7YFUdgxPk1jIke/+nZmuQEt06c9E7Ed7yTx267kfSsL7lvQDd+ursTz/Vvxnp7bXYY64Uw6a4LqJSaRFxnl1vk1pyHeDj3DmzEM8Y2gExS6N2sBje2r8f17YzW257UJmRVN1qOU+3G2NtujauRnBDHfT3dfJHmZ6bQrjjOAJXqQ09Xh+c2u3Ejemdga2MRiQ6GG2+J3RDGpU9dxNP/dU1qia/RlK0DfqHsw8s55+KhXDfyW966cwD/ffp97si9n37Zz2OPN26cDvfQOFtfhlzVn+pVjN/UYntjANpmvc/WG+fh/fs9ro0b+ljb5RyiAn/c3wWAI/X7MqGV0aC5tM+lNOtzK8tH+C78O8Xenp/sF2InjtQ+Rl2nVXGbmHNGZe7sdja/2s0bb6NL4LZpPtPYAYZ2Pot4Mx5JTqrvk+DWOlcCOKedA5yq2pKfn7iW6x56m7x4w103sF1d8spU5ZVc8yZxvZ/okEDNmrXhv7M5dJERluGMc11Py+43vevPr8MzlzXjl3suhDvmOdPrVS3HkNzHqNNjKCre88aXTRJH7t0IFc2lEnu4fgcDcp5j2vC+cOlouG066qxuLH+mN38+2BWAa9vWoWF6Xej8IMmJCeyhCiMqvcJS3djvjaSwWG4ij4OMUX7cG6lpHtPU4+MUTZ5b6RIotzvgtCo30usGI2oerd1+tNUN32XjGkEufsnLPkmXt6zFjSv/4JWrW0JF8weU6NaarNs+8PlSq/pGMGx7CzToFcQIP5Rxi/Vd3XwsDmX2V+/njaGZjS6Gaz5xLs57Q7u6LNx6mDMrluGrRZBY1tc3eU4NMy5EvY4w8hjlgHLgDGW65awb4ZYRrgLXf2nMFjW54OyqbH3pUudKRi3rVCTn/JVs2n+Si6atp1kts/XX8xkyOz9B02d+J9gSzWUSjZtE4xplSbltlpE43IjRkpIYz4qRvUlOiHctImE+fezTlVlQ7VqaHcigzYM/ULZSNY+Y3PXivMKaNr+arHMGsO/p33n16hZUKZtMFcd3WM4QsPotuzizK6WcC13/fF9X3p15JupwXTi00ce/v69iG6YdbcOovIEAjBjYjfoNa/H+jVWcMWW+zevCgsr9eN2tXOMa5WDkMSoBQ4AbLrM74+M4ov8B/HHOi2xbNZ/Pbm3HDf+30GEgjDxGL4CRrqn1N7avxzXnPQYJbj7kxpfA2T3hUtcCFPf2bEhKgiZjbR/SL3vMJ4yDTjU6j+PLlIPrPoevB5Ha4EJSyxv/kfJlDCnqeHYVfl+1h/ds/bn2gTdIr5jI0ToXUXHHn56fv4qDmi3pWxP6tjH7TszPZkjXJlzYsBqTlu2ioRn/vHntCkAFuHM+/PUK1RudT8Yo8zOZZcpgl0egx1Nk4EV8ovN/5HGstvEUVuGMRCqckehdCsfaFB3PrsIfD3TxOR4JLCvgfrnwAfj+Vqcv24lTuF1//N+r3EyY8mhwr//gRuVTEvniNq/hi2f3NGIg9DX/ZrdNDx6of+hfRvxugMveCJzPQcV6noGvCjrypVI63PC1sd3sCuMFVEpNA02XmQAAB7ZJREFU4tNb2pGdZ6NpzXJc0erMkE95bdva5NntDGxX1/PAOX2Nlxvey9AlJcTRtFZ5xg32nLVmrFNp5M0Y1Zd0U5gnDnV97vWqpDL6mpb0OMe1zvbP93TiZJbhQ3c8Bfxxfxf2Hs+Cimk8mHMHs+yt+P6Gnszb1JIulcyyXn0oY2/ydH2kJMZ7NiSUgmsmBO//AJrVqsB7N54Hx3/GnjGfp0615umfVjuPn1uvGrdvdMWBubylcUO4pHlNp0g9kncHtzSs76z/GUm+Q9R8gpt1fQzK1aBP21uAe3zyB8LnPEmpcJNvh/ntXRtBV/+RPutf9SyLfqhC3yvuhsR4ow+nlatD+N4eDalRPoXLmtdk5M/GZ5GYEAcJSVS45TtWfPkkLTa6uUCVnyF5dTvC9gU8eonReLmggZ+wztWbwbVeq2M5Vrey57NcXJg4Fh0JdwHycChZAl7P7CDx5x8Gp5BPsnVCJ6T4zxOIR7caLfnUMB6DlPIMYFM7+B+bWq3Cs+mOucZiuj/dY8zycoST7flM8HJhkpwQz00d08MqkxAfx81hlgnlnP7ocJbnd+K9+EaL2hV9yjSuUc5osQI/2I3WUf2qqdSv6nYTdL+xNLqY3s2CPZaZNPMfrdIv5WsR1+JqbgIPAb+3R0OuaHUm3V+bxcO9G3uWMX+HMzKTnbZ61z8g3Z/wSVo5srdzIeciIaUitLkJlViGdte5dXJ6/UdTEl2/McennmgKn1KKFr0Hg4eA+xHFQd/D6QKEbT2nL8x4Hpr2zz9vGDhi6RehfpcwAS9fKySXgUKTEO6nekbkxg1HjJTyxmvQd660QgTMsQL39WxI98aBlwwrCJPuuoCZ6wKs/NLpfqjbwXAbFBPxcYr0qqlsfcmPm9D8HZ4VgWkGAOVSEimX4vv4HzGGh78epJ8HZldHu4NyfuZ6JKX6HxGWH9WaFMn/prIZS7x6+TAbi2FQsgQ8P6oZj1bz7Odyob/HKyHmebCXazTFlGGdIxJmuXXdSrSuW8n/wV7P+k8v6VQLbxy7D3fMI2hc/CBc3rIW4+dlkJrkJk+V0o0OzTrtYessHzdcLHJVm9okJ8bTt3nRTSy0TjjZSHHyAAd1OaqWK7q7oiCEi8Of77dzvrjJOgbxyZ6d8MWIza45fjqXSqkStM5BiQknW2jKpiFtbyHWGHdzW/L8LK0WFVKiG3s/Pk6JeIdI6RNwQYhBLmoa/lJ/gmDpiTyCIAilGRFwQRAEiyICLgiCYFFEwAVBECyKCLggCIJFEQEXBEGwKCLggiAIFkUEXBAEwaIU61R6pdQBIPzoNgZVgYMRNMcKSJ1LB1Ln0kFh6lxPa+0Txa1YBbwwKKWW+IsFUJKROpcOpM6lg6Kos7hQBEEQLIoIuCAIgkWxkoCPjbYBUUDqXDqQOpcOIl5ny/jABUEQBE+s1AIXBEEQ3BABFwRBsCiWEHCl1MVKqfVKqU1KqeHRtqegKKU+VkrtV0qtckurrJSappTaaL5Xcjv2uFnn9UqpPm7p5ymlVprH3lbK3xLdsYFSqo5SaqZSaq1SarVSapiZXmLrrZRKUUotUkotN+v8rJleYuvsQCkVr5RappT61dwv0XVWSmWYtv6rlFpiphVfnbXWMf0C4oHNwFlAErAcaBptuwpYly5AG2CVW9orwHBzezjwsrnd1KxrMlDf/AzizWOLgI4Y63ZPAS6Jdt2C1Lkm0MbcLgdsMOtWYutt2lfW3E4EFgIdSnKd3er+IPAl8Gsp+X1nAFW90oqtzlZogbcDNmmtt2itc4CJQP8o21QgtNazgcNeyf2BT8ztT4Ar3NInaq2ztdZbgU1AO6VUTaC81nqBNr75T93KxBxa6z1a63/M7RPAWuBMSnC9tcFJczfRfGlKcJ0BlFK1gb7AOLfkEl3nABRbna0g4GcCO9z2d5ppJYXqWus9YIgdUM1MD1TvM81t7/SYRymVDrTGaJGW6HqbroR/gf3ANK11ia8z8CbwKOC+OnNJr7MGpiqlliqlhpppxVZnKyxq7M8XVBrGPgaqtyU/D6VUWeB74H6t9fEgLr4SUW+ttQ1opZSqCExSSp0bJLvl66yUugzYr7VeqpTqFkoRP2mWqrNJJ631bqVUNWCaUmpdkLwRr7MVWuA7gTpu+7WB3VGypSjYZz5CYb7vN9MD1Xunue2dHrMopRIxxPsLrfUPZnKJrzeA1vooMAu4mJJd505AP6VUBoabs4dS6nNKdp3RWu823/cDkzBcvsVWZysI+GKgoVKqvlIqCbge+DnKNkWSn4HB5vZg4Ce39OuVUslKqfpAQ2CR+Uh2QinVweypvtmtTMxh2vgRsFZr/brboRJbb6VUmtnyRilVBrgIWEcJrrPW+nGtdW2tdTrGf3SG1noQJbjOSqlUpVQ5xzbQG1hFcdY52r24Ifb0XooxemEz8GS07SlEPb4C9gC5GHfdW4EqwHRgo/le2S3/k2ad1+PWKw20NX8om4ExmDNqY/EFXIjxOLgC+Nd8XVqS6w20AJaZdV4FPGOml9g6e9W/G65RKCW2zhgj45abr9UObSrOOstUekEQBItiBReKIAiC4AcRcEEQBIsiAi4IgmBRRMAFQRAsigi4IAiCRREBFwRBsCgi4IIgCBbl/wHUoZ5seRK1UQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def running_mean(vals, n=1):\n",
    "    assert n < len(vals)\n",
    "    cumvals = np.array(vals).cumsum()\n",
    "    return (cumvals[n:] - cumvals[:-n]) / n \n",
    "\n",
    "# set smoothing factor\n",
    "n = 5\n",
    "\n",
    "plt.plot(running_mean(mc_ordinary_epslengths, n), label=\"ordinary\")\n",
    "plt.plot(running_mean(mc_weighted_epslengths, n), label=\"weighted\")\n",
    "# plt.hlines(num_episodes)\n",
    "plt.title('Episode lengths MC')\n",
    "# plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "# plt.gca().set_ylim([0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Difference\n",
    "\n",
    "### TO-DO: TD Ordinary Importance Sampling (make it work for gridworld)\n",
    "Copied from TD_lab. Currently on-policy, needs to be off-policy.\n",
    "\n",
    "Confused: do we need value functions instead of q-values? Do we even use importance weights in off-policy TD? Are there more off-policy TD methods besides SARSA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sarsa_importance_sampling(env, behavior_policy, target_policy, num_episodes, weighted=False, \n",
    "                                       discount_factor=1.0, alpha=0.5, seed=42,\n",
    "                                 analyse_states=[(0,2), (0,1), (14,2), (2,1)]):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: Off-policy TD control. Calculates the value function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        target policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        behaviour policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        Q: Q value function, numpy array Q[s,a] -> state-action value.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is a numpy array Q[s,a] -> state-action value.\n",
    "        stats is a list of tuples giving the episode lengths and returns.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Keep track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "#     Q = np.ones((env.nS, env.nA)) * -100\n",
    "    Q = np.zeros((env.env.nS, env.env.nA))\n",
    "    C = np.zeros((env.env.nS, env.env.nA))\n",
    "    \n",
    "    analysis_values = dict((k,[]) for k in analyse_states)\n",
    "    \n",
    "    for i_episode in tqdm(range(num_episodes), position=0):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        W = 1\n",
    "        \n",
    "        behavior_policy.Q = Q\n",
    "        target_policy.Q = Q\n",
    "            \n",
    "        s = env.reset()\n",
    "        a = behavior_policy.sample_action(s)\n",
    "        \n",
    "        while True:\n",
    "            # Take action\n",
    "            s_prime, r, final_state, _ = env.step(a)\n",
    "            \n",
    "            # Sample action at from next state\n",
    "            a_prime = behavior_policy.sample_action(s_prime)                        \n",
    "            \n",
    "            if W == 0:\n",
    "                break\n",
    "            \n",
    "            if weighted:\n",
    "                # Update weight and C\n",
    "                C[s][a] = W\n",
    "                # importance weight is 1 \n",
    "                Q[s][a] += W/C[s][a] * alpha * (r + discount_factor * Q[s_prime][a_prime] - Q[s][a])                \n",
    "            else:\n",
    "                Q[s][a] += W * alpha * (r + discount_factor * Q[s_prime][a_prime] - Q[s][a])                \n",
    "            \n",
    "            W = (target_policy.get_probs(s_prime,a_prime))/(behavior_policy.get_probs(s_prime,a_prime))\n",
    "    \n",
    "            behavior_policy.Q[s][a] = Q[s][a]\n",
    "            target_policy.Q[s][a] = Q[s][a]\n",
    "            \n",
    "            s = s_prime\n",
    "            a = a_prime\n",
    "            \n",
    "            R += r\n",
    "            i += 1 \n",
    "            \n",
    "            if final_state:\n",
    "                break\n",
    "            \n",
    "        stats.append((i, R))\n",
    "\n",
    "        # store state values to analyse\n",
    "        for (s,a) in analyse_states:\n",
    "#             print(Q[s][a])\n",
    "            analysis_values[(s,a)].append(Q[s][a])\n",
    "    \n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    \n",
    "    return Q, episode_lengths, analysis_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using ordinary importance sampling (5000 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 889.29it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using weighted importance sampling (5000 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1144.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reproducible\n",
    "seed = 42\n",
    "\n",
    "# set other parameters\n",
    "epsilon = 0.2\n",
    "gamma = 0.99\n",
    "num_episodes = 5000\n",
    "Q = np.zeros((env.env.nS, env.env.nA))\n",
    "behavioral_policy = EpsilonGreedyPolicy(Q, epsilon=epsilon)\n",
    "target_policy = GreedyPolicy(Q)\n",
    "\n",
    "# the episode length is equal to the negative return. \n",
    "print(f\"Updating Q using ordinary importance sampling ({num_episodes} episodes)\")\n",
    "Q_sarsa_ordinary, sarsa_ordinary_epslengths, sarsa_analysis_ordinary = sarsa_importance_sampling(env, \n",
    "                                                               behavioral_policy, target_policy, \n",
    "                                                               num_episodes, weighted=False,\n",
    "                                                                         discount_factor=gamma, seed=seed)\n",
    "\n",
    "Q = np.zeros((env.env.nS, env.env.nA))\n",
    "behavioral_policy = EpsilonGreedyPolicy(Q, epsilon=epsilon)\n",
    "target_policy = GreedyPolicy(Q)\n",
    "\n",
    "\n",
    "print(f\"Updating Q using weighted importance sampling ({num_episodes} episodes)\")\n",
    "Q_sarsa_weighted, sarsa_weighted_epslengths, sarsa_analysis_weighted = sarsa_importance_sampling(env, \n",
    "                                                                        behavioral_policy, target_policy,\n",
    "                                                                        num_episodes, weighted=True,\n",
    "                                                                        discount_factor=gamma, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_sarsa_importance_sampling(env, behavior_policy, target_policy, num_episodes, n=1, weighted=False, \n",
    "                                       discount_factor=1.0, alpha=0.5, seed=42,\n",
    "                                 analyse_states=[(0,2), (0,1), (14,2), (2,1)]):\n",
    "\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Keep track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    Q = np.zeros((env.env.nS, env.env.nA))\n",
    "    C = np.zeros((env.env.nS, env.env.nA))\n",
    "    \n",
    "    analysis_values = dict((k,[]) for k in analyse_states)\n",
    "    \n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        behavior_policy.Q = Q\n",
    "        target_policy.Q = Q\n",
    "        \n",
    "        s = defaultdict(lambda: defaultdict(float))\n",
    "        a = defaultdict(lambda: defaultdict(float))\n",
    "        r = defaultdict(lambda: defaultdict(float))\n",
    "            \n",
    "        s[0] = env.reset()\n",
    "        a[0] = behavior_policy.sample_action(s[0])\n",
    "        \n",
    "        T = np.inf\n",
    "        t = 0\n",
    "        while True:\n",
    "            if t < T:\n",
    "                # Take action\n",
    "                s[t+1], r[t+1], final_state, _ = env.step(a[t])\n",
    "                R += r[t+1]\n",
    "                i += 1\n",
    "                \n",
    "                if final_state:\n",
    "                    T = t + 1\n",
    "                else:\n",
    "                    # Sample action from next state\n",
    "                    a[t+1] = behavior_policy.sample_action(s[t+1])\n",
    "            \n",
    "            tau = t - n + 1\n",
    "            \n",
    "            if tau >= 0:\n",
    "                # Collect states and actions included in ratio\n",
    "                last_step_rho = min([tau + n, T - 1])\n",
    "                first_step = tau + 1\n",
    "                states = [value for key, value in s.items() if key in range(first_step, last_step_rho+1)]\n",
    "                actions = [value for key, value in a.items() if key in range(first_step, last_step_rho+1)]\n",
    "                \n",
    "                # n-step importance sampling ratio\n",
    "                rho = np.prod([(target_policy.get_probs([state],[action]))/(behavior_policy.get_probs([state],[action])) for state, action in zip(states, actions)])\n",
    "                \n",
    "                # n-step return\n",
    "                last_step_G = min([tau + n, T])\n",
    "                G = np.sum([discount_factor**(i - tau - 1) * r[i] for i in range(first_step, last_step_G)])\n",
    "                if tau + n < T:\n",
    "                    G += discount_factor**n * Q[s[tau+n]][a[tau+n]]\n",
    "\n",
    "                # Update Q - ordinary importance sampling: divided by number of steps? \n",
    "                if (weighted):\n",
    "                    Q[s[tau]][a[tau]] += alpha * rho * (G - Q[s[tau]][a[tau]]) / (last_step_rho+1 - first_step)\n",
    "                else:\n",
    "                    Q[s[tau]][a[tau]] += (alpha * (G - Q[s[tau]][a[tau]]) / (last_step_rho+1 - first_step))\n",
    "\n",
    "            if tau == T - 1:\n",
    "                break\n",
    "                         \n",
    "            t += 1\n",
    "\n",
    "        stats.append((i, R))\n",
    "        \n",
    "#     Q = Qdefaultdict2array(Q, env.nA, env.nS)\n",
    "        \n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using ordinary importance sampling (5000 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/rl2020/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1600592683d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                                \u001b[0mbehavioral_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                                \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                                          discount_factor=gamma, seed=seed)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-cc60e78d5d1c>\u001b[0m in \u001b[0;36mn_step_sarsa_importance_sampling\u001b[0;34m(env, behavior_policy, target_policy, num_episodes, n, weighted, discount_factor, alpha, seed, analyse_states)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;31m# Sample action from next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehavior_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-42dcf3f3db1a>\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# choose one of the best actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# return a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Reproducible\n",
    "seed = 42\n",
    "\n",
    "# set other parameters\n",
    "epsilon = 0.2\n",
    "gamma = 0.99\n",
    "num_episodes = 5000\n",
    "Q = np.zeros((env.env.nS, env.env.nA))\n",
    "behavioral_policy = EpsilonGreedyPolicy(Q, epsilon=epsilon)\n",
    "target_policy = GreedyPolicy(Q)\n",
    "\n",
    "# the episode length is equal to the negative return. \n",
    "print(f\"Updating Q using ordinary importance sampling ({num_episodes} episodes)\")\n",
    "Q_sarsa_ordinary, sarsa_ordinary_epslengths, sarsa_analysis_ordinary = n_step_sarsa_importance_sampling(env, \n",
    "                                                               behavioral_policy, target_policy, \n",
    "                                                               num_episodes, n=4, weighted=False,\n",
    "                                                                         discount_factor=gamma, seed=seed)\n",
    "\n",
    "Q = np.zeros((env.env.nS, env.env.nA))\n",
    "behavioral_policy = EpsilonGreedyPolicy(Q, epsilon=epsilon)\n",
    "target_policy = GreedyPolicy(Q)\n",
    "\n",
    "\n",
    "print(f\"Updating Q using weighted importance sampling ({num_episodes} episodes)\")\n",
    "Q_sarsa_weighted, sarsa_weighted_epslengths, sarsa_analysis_weighted = n_step_sarsa_importance_sampling(env, \n",
    "                                                               behavioral_policy, target_policy, \n",
    "                                                               num_episodes, n=4, weighted=True,\n",
    "                                                                         discount_factor=gamma, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(env, policy, Q, num_episodes, discount_factor=1.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: On-policy TD control. Finds the optimal epsilon-greedy policy.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        Q: Q value function, numpy array Q[s,a] -> state-action value.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is a numpy array Q[s,a] -> state-action value.\n",
    "        stats is a list of tuples giving the episode lengths and returns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        # initial state is 3,0 in the grid (according to source code)\n",
    "        s = env.reset()\n",
    "        a = policy.sample_action(s)\n",
    "        final_state_reached = False\n",
    "        \n",
    "        while True:\n",
    "            # new actions\n",
    "            s_prime, r, final_state, _ = env.step(a)\n",
    "            \n",
    "            # keep track of stats\n",
    "            R += r\n",
    "            i += 1    \n",
    "            \n",
    "            # sample action at state s_prime\n",
    "            a_prime = policy.sample_action(s_prime)\n",
    "\n",
    "            # update Q \n",
    "            Q[s][a] += alpha * (r + discount_factor * Q[s_prime][a_prime] - Q[s][a])    \n",
    "    \n",
    "            # update policy\n",
    "            policy.Q = Q\n",
    "            \n",
    "            # if final state, terminate loop\n",
    "            if final_state:\n",
    "                break\n",
    "        \n",
    "            # update current s and a for next iteration\n",
    "            s = s_prime\n",
    "            a = a_prime\n",
    "            \n",
    "        stats.append((i, R))\n",
    "        \n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa_ordinary_importance_sampling(env, behavior_policy, target_policy, num_episodes, discount_factor=1.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: Off-policy TD control. Calculates the value function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        Q: Q value function, numpy array Q[s,a] -> state-action value.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is a numpy array Q[s,a] -> state-action value.\n",
    "        stats is a list of tuples giving the episode lengths and returns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    Q = np.ones((env.nS, env.nA)) * -100\n",
    "    \n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        behavior_policy.Q = Q\n",
    "        target_policy.Q = Q\n",
    "            \n",
    "        s = env.reset()\n",
    "        a = behavior_policy.sample_action(s)\n",
    "        \n",
    "        while True:\n",
    "            # Take action\n",
    "            s_prime, r, final_state, _ = env.step(a)\n",
    "            \n",
    "            # Sample action at from next state\n",
    "            a_prime = behavior_policy.sample_action(s_prime)\n",
    "            \n",
    "            # Update weight\n",
    "            W = (target_policy.get_probs([s_prime],[a_prime]))/(behavior_policy.get_probs([s_prime],[a_prime]))\n",
    "\n",
    "            # Update Q \n",
    "            Q[s][a] += alpha * W * (r + discount_factor * Q[s_prime][a_prime] - Q[s][a])    \n",
    "            \n",
    "            s = s_prime\n",
    "            a = a_prime\n",
    "            \n",
    "            R += r\n",
    "            i += 1 \n",
    "            \n",
    "            if final_state:\n",
    "                break\n",
    "            \n",
    "        stats.append((i, R))\n",
    "        \n",
    "#     Q = Qdefaultdict2array(Q, env.nA, env.nS)\n",
    "        \n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "env.render()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_sarsa_ordinary_importance_sampling(env, behavior_policy, target_policy, num_episodes, n=1, discount_factor=1.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    n-step SARSA algorithm: Off-policy TD control. Calculates the value function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        Q: Q value function, numpy array Q[s,a] -> state-action value.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        n: number of steps\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is a numpy array Q[s,a] -> state-action value.\n",
    "        stats is a list of tuples giving the episode lengths and returns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "#     Q = np.ones((env.nS, env.nA)) * -100\n",
    "    \n",
    "    Q = np.zeros((env.env.nS, env.env.nA))\n",
    "    C = np.zeros((env.env.nS, env.env.nA))\n",
    "    \n",
    "    analysis_values = dict((k,[]) for k in analyse_states)\n",
    "    \n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        behavior_policy.Q = Q\n",
    "        target_policy.Q = Q\n",
    "        \n",
    "        s = defaultdict(lambda: defaultdict(float))\n",
    "        a = defaultdict(lambda: defaultdict(float))\n",
    "        r = defaultdict(lambda: defaultdict(float))\n",
    "            \n",
    "        s[0] = env.reset()\n",
    "        a[0] = behavior_policy.sample_action(s[0])\n",
    "        \n",
    "        T = np.inf\n",
    "        t = 0\n",
    "        while True:\n",
    "            if t < T:\n",
    "                # Take action\n",
    "                s[t+1], r[t+1], final_state, _ = env.step(a[t])\n",
    "                R += r[t+1]\n",
    "                i += 1\n",
    "                \n",
    "                if final_state:\n",
    "                    T = t + 1\n",
    "                else:\n",
    "                    # Sample action from next state\n",
    "                    a[t+1] = behavior_policy.sample_action(s[t+1])\n",
    "            \n",
    "            tau = t - n + 1\n",
    "            \n",
    "            if tau >= 0:\n",
    "                # Collect states and actions included in ratio\n",
    "                last_step_rho = min([tau + n, T - 1])\n",
    "                first_step = tau + 1\n",
    "                states = [value for key, value in s.items() if key in range(first_step, last_step_rho+1)]\n",
    "                actions = [value for key, value in a.items() if key in range(first_step, last_step_rho+1)]\n",
    "                \n",
    "                # n-step importance sampling ratio\n",
    "                rho = np.prod([(target_policy.get_probs([state],[action]))/(behavior_policy.get_probs([state],[action])) for state, action in zip(states, actions)])\n",
    "                \n",
    "                # n-step return\n",
    "                last_step_G = min([tau + n, T])\n",
    "                G = np.sum([discount_factor**(i - tau - 1) * r[i] for i in range(first_step, last_step_G)])\n",
    "                if tau + n < T:\n",
    "                    G += discount_factor**n * Q[s[tau+n]][a[tau+n]]\n",
    "\n",
    "                # Update Q - ordinary importance sampling: divided by number of steps? \n",
    "                Q[s[tau]][a[tau]] += alpha * rho * (G - Q[s[tau]][a[tau]]) / (last_step_rho+1 - first_step)\n",
    "\n",
    "            if tau == T - 1:\n",
    "                break\n",
    "                         \n",
    "            t += 1\n",
    "\n",
    "        stats.append((i, R))\n",
    "        \n",
    "    Q = Qdefaultdict2array(Q, env.nA, env.nS)\n",
    "        \n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO: TD Weighted Importance Sampling (same as above but weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TD weighted importance sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa_weigthed_importance_sampling(env, behavior_policy, target_policy, num_episodes, discount_factor=1.0, alpha=0.5):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: Off-policy TD control. Calculates the value function\n",
    "    for a given target policy using behavior policy and ordinary importance sampling.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        target policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        behaviour policy: A policy which allows us to sample actions with its sample_action method.\n",
    "        Q: Q value function, numpy array Q[s,a] -> state-action value.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is a numpy array Q[s,a] -> state-action value.\n",
    "        stats is a list of tuples giving the episode lengths and returns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    Q = np.ones((env.nS, env.nA))\n",
    "    C = np.zeros((env.nS, env.nA))\n",
    "    \n",
    "    s = defaultdict(lambda: defaultdict(float))\n",
    "    a = defaultdict(lambda: defaultdict(float))\n",
    "    r = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    s[0] = env.reset()\n",
    "    a[0] = behavior_policy.sample_action(s[0])\n",
    "    \n",
    "    T = np.inf\n",
    "    t = 0\n",
    "    while True:\n",
    "        if t < T:\n",
    "            # Take action\n",
    "            s[t+1], r[t+1], final_state, _ = env.step(a[t])\n",
    "            R += r[t+1]\n",
    "            i += 1\n",
    "\n",
    "            if final_state:\n",
    "                T = t + 1\n",
    "            else:\n",
    "                # Sample action from next state\n",
    "                a[t+1] = behavior_policy.sample_action(s[t+1])\n",
    "\n",
    "        tau = t - n + 1\n",
    "\n",
    "        if tau >= 0:\n",
    "            # Collect states and actions included in ratio\n",
    "            last_step_rho = min([tau + n, T - 1])\n",
    "            first_step = tau + 1\n",
    "            states = [value for key, value in s.items() if key in range(first_step, last_step_rho+1)]\n",
    "            actions = [value for key, value in a.items() if key in range(first_step, last_step_rho+1)]\n",
    "\n",
    "        # n-step importance sampling ratio\n",
    "#             rho = np.prod([(target_policy.get_probs([state],[action]))/(behavior_policy.get_probs([state],[action])) for state, action in zip(states, actions)])\n",
    "\n",
    "        # n-step return\n",
    "        last_step_G = min([tau + n, T])\n",
    "        G = np.sum([discount_factor**(i - tau - 1) * r[i] for i in range(first_step, last_step_G)])\n",
    "        if tau + n < T:\n",
    "            G += discount_factor**n * Q[s[tau+n]][a[tau+n]]\n",
    "\n",
    "        # Update Q - for weigted sampling rho/rho is 1 \n",
    "        Q[s[tau]][a[tau]] += alpha * (G - Q[s[tau]][a[tau]])\n",
    "\n",
    "        if tau == T - 1:\n",
    "            break\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    stats.append((i, R))\n",
    "        \n",
    "    Q = Qdefaultdict2array(Q, env.nA, env.nS)\n",
    "        \n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using ordinary importance sampling (100 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 67.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Q using ordinary importance sampling (100 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'R' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7c5ab87aadb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Updating Q using ordinary importance sampling ({num_episodes} episodes)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m Q_td_nstep_weigthed, td_nstep_weighted_epsstats = sarsa_weigthed_importance_sampling(env, behavioral_policy, target_policy, \n\u001b[0;32m---> 22\u001b[0;31m                                                                         num_episodes, discount_factor, alpha)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-79172c458b63>\u001b[0m in \u001b[0;36msarsa_weigthed_importance_sampling\u001b[0;34m(env, behavior_policy, target_policy, num_episodes, discount_factor, alpha)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Take action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mR\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'R' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Reproducible\n",
    "np.random.seed(42)\n",
    "\n",
    "# set other parameters\n",
    "epsilon = 0.05\n",
    "discount_factor = 1.0\n",
    "num_episodes = 100\n",
    "alpha=0.5\n",
    "Q = np.ones((env.nS, env.nA)) * -100\n",
    "behavioral_policy = EpsilonGreedyPolicy(Q, epsilon=epsilon)\n",
    "target_policy = GreedyPolicy(Q)\n",
    "\n",
    "# the episode length is equal to the negative return. \n",
    "print(f\"Updating Q using ordinary importance sampling ({num_episodes} episodes)\")\n",
    "Q_td_ordinary, td_ordinary_epsstats = sarsa_ordinary_importance_sampling(env, behavioral_policy, target_policy, \n",
    "                                                                        num_episodes, discount_factor, alpha)\n",
    "\n",
    "n=4\n",
    "# the episode length is equal to the negative return. \n",
    "print(f\"Updating Q using ordinary importance sampling ({num_episodes} episodes)\")\n",
    "Q_td_nstep_weigthed, td_nstep_weighted_epsstats = sarsa_weigthed_importance_sampling(env, behavioral_policy, target_policy, \n",
    "                                                                        num_episodes, discount_factor, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ,import plotly.graph_objects as go\n",
    "\n",
    "n = 5\n",
    "\n",
    "rm = running_mean(td_nstep_ordinary_epsstats[0], n)\n",
    "\n",
    "# fig = go.Figure(go.Scatter(x=list(range(len(rm))), y=rm))\n",
    "# fig.show()\n",
    "\n",
    "plt.plot(rm, label=\"ordinary\")\n",
    "plt.title('Episode lengths TD')\n",
    "plt.legend()\n",
    "# plt.gca().set_ylim([0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
